from datetime import datetime
import pandas as pd
import os
import re
import json

# ignore all warnings
import warnings
warnings.filterwarnings("ignore")

from app.services.logger import log
from VARIABLES import coding_model, analytical_model , cot_model
from app.services.code_execution_agent import extract_code, execute_code
from app.services.code_evaluation_agent import code_evaluation
from app.services.brain import use_brain
from app.pipelines.smart_query import append_suggestions_to_output


project_dir = os.getcwd()

##MARK:Extract the graph parameters
def extract_graph_parameters(prompt, df_columns, userName):
    """
    Enhanced version that incorporates personalization and better error handling
    """
    system_prompt = f"""You are AERO DATA AI, a data analysis expert assisting {userName}. Given a natural language query about plotting a graph and available columns, determine:
    1. Which column should be on the x-axis
    2. Which column(s) should be on the y-axis (can be multiple)
    3. What type of graph would be most appropriate (area, line, bar, pie)
    
    ONLY choose columns that exist in the available columns list. Double-check your selection against the provided column list.
    
    Respond in JSON format like:
    {{
        "x_axis": "column_name",
        "y_axis": ["column_name1", "column_name2"],
        "graph_type": "line",
        "explanation": "Brief explanation of why these choices were made"
    }}
    """
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "system", "content": f"Available columns: {df_columns}"},
        {"role": "user", "content": prompt}
    ]
    
    try:
        response = use_brain(messages=messages, model=coding_model)
        log(f"LLM Response: {response.strip()}")
        
        # Improved JSON extraction using regex
        json_pattern = r'\{[\s\S]*\}'
        json_match = re.search(json_pattern, response.strip())
        if not json_match:
            raise ValueError("No valid JSON object found in response")
        
        json_str = json_match.group(0)
        params = json.loads(json_str)
        
        required_keys = ["x_axis", "y_axis", "graph_type", "explanation"]
        missing_keys = [key for key in required_keys if key not in params]
        if missing_keys:
            log(f"Missing keys in LLM response: {missing_keys} | Raw Response: {params}")
            raise ValueError(f"Invalid JSON response: Missing keys {missing_keys}")
        
        # Validate columns against available columns
        if params["x_axis"] not in df_columns:
            raise ValueError(f"Selected x-axis column '{params['x_axis']}' is not in available columns")
            
        # Ensure y_axis is always a list
        if isinstance(params["y_axis"], str):
            params["y_axis"] = [params["y_axis"]]
            
        # Validate y-axis columns
        invalid_cols = [col for col in params["y_axis"] if col not in df_columns]
        if invalid_cols:
            raise ValueError(f"Selected y-axis column(s) {invalid_cols} are not in available columns")
        
        # Validate graph_type
        valid_types = ["area", "line", "bar", "pie"]
        if params["graph_type"] not in valid_types:
            raise ValueError(f"Invalid graph type: {params['graph_type']}. Must be one of {valid_types}")
        
        return params
    except json.JSONDecodeError as e:
        log(f"JSON Parsing Error: {str(e)} | Raw Response: {response.strip()}")
        raise ValueError("Could not parse LLM response to valid JSON")
    except Exception as e:
        log(f"Error in parameter extraction: {str(e)}")
        raise ValueError(f"Error in parameter extraction: {str(e)}")


##MARK:Generating the graph 
def get_response(prompt, fileName, userName, Gen_JSON_name):
    """
    Fetch response from the LLM containing python code for user's query

    Args:
        prompt (str): User's prompt
        fileName (str): Name of the user's CSV file
        userName (str): User's name for personalization
        Gen_JSON_name (str): Target JSON filename for graph data
        
    Returns:
        Raw output generated by the LLM
    """
    file_path = f'{project_dir}/Uploads/{fileName}'
    log(f"Loading file from: {file_path}")
    
    # Handle file loading with better error reporting
    try:
        df = pd.read_csv(file_path)
        log(f"Successfully loaded file with {len(df)} rows and {len(df.columns)} columns")
    except FileNotFoundError:
        error_msg = f"File not found at {file_path}. Please check if the file exists."
        log(error_msg)
        return f"Error: {error_msg}"
    except Exception as e:
        error_msg = f"Error loading file: {str(e)}"
        log(error_msg)
        return f"Error: {error_msg}"
    
    column_headers = df.columns.tolist()
    
    try:
        graph_params = extract_graph_parameters(prompt, column_headers, userName)
        log(f"Extracted graph parameters: {graph_params}")
    except ValueError as e:
        log(f"Error extracting graph parameters: {str(e)}")
        return f"I apologize, but I couldn't properly analyze your request. Error: {str(e)}"

    base_system_prompt = f"""You are AERO DATA AI, a data analyst expert specialized in preparing data for visualization. Your task is to generate visualization data with appropriate aggregation.

    FILE: {file_path}
    OUTPUT file path: f'{project_dir}/GeneratedJSON/{Gen_JSON_name}'

    Generate Python code that:
    1. Uses pandas for data manipulation
    2. Handles missing values appropriately
    3. Performs data type conversions
    4. Creates appropriate aggregations based on data types
    5. Generates JSON output in the specified format.
    6. Creates dynamic aggregations based on dataset size:
       - If data is small, use daily aggregation
       - If data is large or medium, aggregate by month or quarter
    7.Formats timestamps into a human-readable format (YYYY-MM-DD) before saving
    8.Always use the relative path while writing the code using the llm 
    

    RULES:
    1. NO sample code or templates
    2. NO print statements except for success message
    3. MUST include error handling
    4. MUST validate data types
    5. MUST handle edge cases
    6. Code MUST be complete and executable
    7. Generate ONLY code, no explanations
    8.Always import the warnings module and ignore all warnings
    9. Gnerate the 50-60 words summary of the graph
    10.Do nor give this in output :JSON file generated successfully.



     CRITICAL INSTRUCTIONS:
    1. Use ABSOLUTE file paths for both input and output files
    2. Make sure to handle path issues with proper error checking
    

        
     Save result in this JSON structure:
        {{
            "graph_type": "{graph_params['graph_type']}",
            "data_points": [
                {{
                    "{graph_params['x_axis']}": "value",
                    "{graph_params['y_axis'][0]}": number
                }}
            ]
        }}

    
        """
    
    messages = [
        {'role': 'system', 'content': base_system_prompt},
        {'role': 'system', 'content': f"Available columns in dataset:\n{column_headers}"},
        {'role': 'user', 'content': prompt}
    ]

    response = use_brain(messages=messages, model=cot_model)
    return response



def extract_graph_summary(json_file_path):
    """
    Extract and generate a 50-60 word summary from the graph JSON data.
    
    Args:
        json_file_path: Path to the generated JSON file
        
    Returns:
        A concise summary of the graph data
    """
    try:
        # Load the JSON data
        with open(json_file_path, 'r') as f:
            graph_data = json.load(f)
        
        # Extract key information
        graph_type = graph_data.get('graph_type', 'unknown')
        data_points = graph_data.get('data_points', [])
        
        # If there's already a summary field, use it
        if 'summary' in graph_data:
            return graph_data['summary']
        
        # Otherwise, generate a summary using the LLM
        messages = [
            {"role": "system", "content": """You are a data analysis expert. Generate a concise 50-60 word summary of 
            the graph data provided. Focus on key trends, patterns, outliers, and insights. Keep your language clear 
            and objective. The summary should be a single paragraph with no bullet points or formatting."""},
            {"role": "user", "content": f"Graph type: {graph_type}\nData points: {str(data_points)[:1000]}\n\nGenerate a 50-60 word summary."}
        ]
        
        summary = use_brain(messages=messages, model=cot_model)
        

        
        return summary.strip()
        
    except Exception as e:
        log(f"Error generating graph summary: {str(e)}")
        return "Unable to generate a summary for this graph due to an error."

  

def trigger_graph_pipeline(prompt, fileName, userName, max_attempts=3, current_attempt=1):
    '''
    Trigger the Graph pipeline with improved error handling and retry mechanism
    
    Args:
        prompt (str): User's prompt for the LLM
        fileName (str): Name of the user's CSV file
        userName (str): User's name for personalization
        max_attempts (int): Maximum number of retry attempts
        current_attempt (int): Current attempt number
        
    Returns:
        tuple: (JSON filename or None, Output message)
    '''
    # Prevent infinite recursion
    if current_attempt > max_attempts:
        log(f"Maximum retry attempts ({max_attempts}) reached")
        return None, "I'm sorry, but I couldn't generate your graph after multiple attempts. Please try rephrasing your request or contact support."

    now = datetime.now()
    Gen_JSON_name = f'{now.strftime("ADAI_Json_%d_%m_%H_%M_%S")}.json'
    initial_response = get_response(prompt, fileName, userName, Gen_JSON_name)

    log(f'Initial Response has been received')

    code = extract_code(initial_response)
    
    # Handle case where no valid code was extracted
    if code is None:
        log(f"No valid code extracted on attempt {current_attempt}/{max_attempts}")
        if current_attempt < max_attempts:
            log(f"Retrying graph generation (attempt {current_attempt+1}/{max_attempts})")
            return trigger_graph_pipeline(prompt, fileName, userName, max_attempts, current_attempt+1)
        else:
            return None, "I'm sorry, but I couldn't generate the code for your graph. Please try rephrasing your request."

    # Record the exit code by execution of code and code's output
    exit_code, initial_output = execute_code(code)

    # Check if the code execution was successful or not
    if exit_code == 0:  # Code execution was successful
        log(f'Code execution successful. Output: {initial_output}')

        # Check if the file has been generated successfully
        if os.path.isfile(f'GeneratedJSON/{Gen_JSON_name}'):
            log(f'The file {Gen_JSON_name} exists in the GeneratedJSON folder.')
            
            # Extract a summary from the graph data
            graph_summary = extract_graph_summary(f'GeneratedJSON/{Gen_JSON_name}')
            
            # Combine the original output with the graph summary
            combined_output = f"{initial_output}\n\nGraph Summary: {graph_summary}"
            
            # Add query suggestions to the output
            enhanced_output = append_suggestions_to_output(combined_output)
            return Gen_JSON_name, enhanced_output
        else:
            log(f"File not found despite successful code execution: {Gen_JSON_name}")
            
            # Attempt to verify what happened
            try:
                files_in_dir = os.listdir('GeneratedJSON')
                log(f"Files in GeneratedJSON: {files_in_dir}")
                
                # Check if the directory was created at all
                if not os.path.exists('GeneratedJSON'):
                    log("GeneratedJSON directory does not exist!")
            except Exception as e:
                log(f"Error checking directory: {str(e)}")
            
            if current_attempt < max_attempts:
                log(f"Retrying graph generation (attempt {current_attempt+1}/{max_attempts})")
                return trigger_graph_pipeline(prompt, fileName, userName, max_attempts, current_attempt+1)
            else:
                return None, "There was an error in generating your requested Graph. The code executed successfully but the output file was not created."
    
    else:  # Code execution failed
        log(f"Code execution failed with exit code {exit_code}. Error: {initial_output}")
        
        # Special handling for common error patterns
        if "FileNotFoundError" in initial_output:
            log("File not found error detected - revising file path handling")
            file_path_error_prompt = f"""
            Your code failed with a FileNotFoundError. 
            
            IMPORTANT: You MUST use this EXACT file path to load the CSV:
            '{project_dir}/Uploads/{fileName}'
            
            Do not use any other path or filename. The file exists at this location.
            
            Original error: {initial_output}
            """
            evaluated_output = code_evaluation(fileName=fileName, generated_code=code, error=file_path_error_prompt)
        else:
            # General error handling
            evaluated_output = code_evaluation(fileName=fileName, generated_code=code, error=initial_output)
        
        evaluated_code = extract_code(evaluated_output)
        
        # Handle case where no valid code was extracted from evaluation
        if evaluated_code is None:
            log(f"No valid code extracted from evaluation on attempt {current_attempt}/{max_attempts}")
            if current_attempt < max_attempts:
                log(f"Retrying graph generation (attempt {current_attempt+1}/{max_attempts})")
                return trigger_graph_pipeline(prompt, fileName, userName, max_attempts, current_attempt+1)
            else:
                return None, "I'm sorry, but I couldn't generate the code for your graph after multiple attempts."
        
        # Execute the newly generated code 
        new_exit_code, new_code_output = execute_code(evaluated_code)

        log(f"Evaluated code execution result: Exit code: {new_exit_code}, Output: {new_code_output}")

        if new_exit_code == 0:  # Code execution was successful            
            # Check if the file has been generated successfully
            if os.path.isfile(f'GeneratedJSON/{Gen_JSON_name}'):
                log(f'The file {Gen_JSON_name} exists in the GeneratedJSON folder')
                # Add query suggestions to the output
                enhanced_output = append_suggestions_to_output(new_code_output)
                return Gen_JSON_name, enhanced_output
            else:
                log(f"File not found after evaluation: {Gen_JSON_name}")
                if current_attempt < max_attempts:
                    log(f"Retrying graph generation (attempt {current_attempt+1}/{max_attempts})")
                    return trigger_graph_pipeline(prompt, fileName, userName, max_attempts, current_attempt+1)
                else:
                    return None, "There was an error in generating your requested Graph. The code executed successfully but the output file was not created."
        else:
            log(f"Evaluated code execution failed on attempt {current_attempt}/{max_attempts}")
            if current_attempt < max_attempts:
                log(f"Retrying graph generation (attempt {current_attempt+1}/{max_attempts})")
                return trigger_graph_pipeline(prompt, fileName, userName, max_attempts, current_attempt+1)
            else:
                return None, "There was an error in generating your requested Graph."
            

            